{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.mean=0.4802024482630155\n",
      "loss.mean=0.41946053767487257\n",
      "loss.mean=0.3703146053091112\n",
      "loss.mean=0.33010736457692164\n",
      "loss.mean=0.29683976773924464\n",
      "loss.mean=0.26901033716205247\n",
      "loss.mean=0.2454868325817521\n",
      "loss.mean=0.2254092792376342\n",
      "loss.mean=0.20811861929372028\n",
      "loss.mean=0.19310480097935254\n",
      "loss.mean=0.17996910067031546\n",
      "loss.mean=0.16839669998151433\n",
      "loss.mean=0.15813661069196466\n",
      "loss.mean=0.14898686740825665\n",
      "loss.mean=0.14078351259024305\n",
      "loss.mean=0.13339232917103505\n",
      "loss.mean=0.12670257900271087\n",
      "loss.mean=0.12062221776301556\n",
      "loss.mean=0.11507420600939572\n",
      "loss.mean=0.10999364107684464\n",
      "loss.mean=0.10532550892569742\n",
      "loss.mean=0.10102290813378893\n",
      "loss.mean=0.09704563638740246\n",
      "loss.mean=0.09335905746919863\n",
      "loss.mean=0.08993318692567762\n",
      "loss.mean=0.08674194945110557\n",
      "loss.mean=0.08376257204196605\n",
      "loss.mean=0.08097508520950375\n",
      "loss.mean=0.07836191073682626\n",
      "loss.mean=0.07590751916769006\n",
      "loss.mean=0.07359814380342901\n",
      "loss.mean=0.07142154074360976\n",
      "loss.mean=0.06936678664065027\n",
      "loss.mean=0.06742410750041325\n",
      "loss.mean=0.06558473316217446\n",
      "loss.mean=0.06384077311637552\n",
      "loss.mean=0.06218511013035531\n",
      "loss.mean=0.06061130879857835\n",
      "loss.mean=0.05911353665109273\n",
      "loss.mean=0.05768649586987148\n",
      "loss.mean=0.056325363998735334\n",
      "loss.mean=0.055025742305292356\n",
      "loss.mean=0.053783610675650795\n",
      "loss.mean=0.05259528810464838\n",
      "loss.mean=0.05145739799391266\n",
      "loss.mean=0.05036683759347564\n",
      "loss.mean=0.0493207510248699\n",
      "loss.mean=0.048316505408584016\n",
      "loss.mean=0.047351669689609535\n",
      "loss.mean=0.04642399581410956\n",
      "loss.mean=0.0455314019600262\n",
      "loss.mean=0.04467195756637747\n",
      "loss.mean=0.043843869941419804\n",
      "loss.mean=0.043045472259867976\n",
      "loss.mean=0.04227521278486981\n",
      "loss.mean=0.04153164517216245\n",
      "loss.mean=0.04081341973240324\n",
      "loss.mean=0.040119275543567826\n",
      "loss.mean=0.03944803331896283\n",
      "loss.mean=0.0387985889481513\n",
      "loss.mean=0.03816990763822875\n",
      "loss.mean=0.03756101859165482\n",
      "loss.mean=0.03697101016444396\n",
      "loss.mean=0.03639902545511744\n",
      "loss.mean=0.03584425828056245\n",
      "loss.mean=0.03530594949995222\n",
      "loss.mean=0.03478338365225804\n",
      "loss.mean=0.03427588587671528\n",
      "loss.mean=0.033782819088966166\n",
      "loss.mean=0.03330358138855523\n",
      "loss.mean=0.03283760367605248\n",
      "loss.mean=0.03238434746037171\n",
      "loss.mean=0.03194330283887567\n",
      "loss.mean=0.031513986634650666\n",
      "loss.mean=0.03109594067692059\n",
      "loss.mean=0.030688730211978404\n",
      "loss.mean=0.030291942433265207\n",
      "loss.mean=0.02990518512034124\n",
      "loss.mean=0.02952808537748649\n",
      "loss.mean=0.02916028846355515\n",
      "loss.mean=0.028801456705500942\n",
      "loss.mean=0.02845126848869978\n",
      "loss.mean=0.028109417317831814\n",
      "loss.mean=0.02777561094265603\n",
      "loss.mean=0.02744957054352267\n",
      "loss.mean=0.02713102997193068\n",
      "loss.mean=0.026819735041852172\n",
      "loss.mean=0.026515442867921273\n",
      "loss.mean=0.02621792124692216\n",
      "loss.mean=0.025926948079317547\n",
      "loss.mean=0.02564231082783481\n",
      "loss.mean=0.025363806010378142\n",
      "loss.mean=0.025091238724761492\n",
      "loss.mean=0.024824422202964044\n",
      "loss.mean=0.024563177392796613\n",
      "loss.mean=0.024307332565038316\n",
      "loss.mean=0.024056722944257362\n",
      "loss.mean=0.02381119036167169\n",
      "loss.mean=0.02357058292853357\n",
      "loss.mean=0.023334754728640487\n",
      "loss.mean=0.02310356552868155\n",
      "loss.mean=0.022876880505227463\n",
      "loss.mean=0.022654569987261834\n",
      "loss.mean=0.02243650921323403\n",
      "loss.mean=0.022222578101689604\n",
      "loss.mean=0.022012661034603243\n",
      "loss.mean=0.021806646652603387\n",
      "loss.mean=0.021604427661335565\n",
      "loss.mean=0.021405900648266217\n",
      "loss.mean=0.021210965909277065\n",
      "loss.mean=0.021019527284447014\n",
      "loss.mean=0.020831492002459838\n",
      "loss.mean=0.020646770533114776\n",
      "loss.mean=0.02046527644745341\n",
      "loss.mean=0.020286926285048752\n",
      "loss.mean=0.020111639428033276\n",
      "loss.mean=0.019939337981471246\n",
      "loss.mean=0.019769946659706022\n",
      "loss.mean=0.019603392678338393\n",
      "loss.mean=0.019439605651513377\n",
      "loss.mean=0.01927851749421455\n",
      "loss.mean=0.019120062329283993\n",
      "loss.mean=0.018964176398903722\n",
      "loss.mean=0.018810797980291637\n",
      "loss.mean=0.018659867305380096\n",
      "loss.mean=0.018511326484259714\n",
      "loss.mean=0.01836511943218466\n",
      "loss.mean=0.018221191799947932\n",
      "loss.mean=0.018079490907446955\n",
      "loss.mean=0.017939965680270394\n",
      "loss.mean=0.01780256658914771\n",
      "loss.mean=0.017667245592111892\n",
      "loss.mean=0.017533956079234917\n",
      "loss.mean=0.01740265281980369\n",
      "loss.mean=0.017273291911811976\n",
      "loss.mean=0.017145830733650703\n",
      "loss.mean=0.017020227897886323\n",
      "loss.mean=0.016896443207022757\n",
      "loss.mean=0.01677443761114838\n",
      "loss.mean=0.01665417316737545\n",
      "loss.mean=0.016535613000984\n",
      "loss.mean=0.016418721268187532\n",
      "loss.mean=0.016303463120442153\n",
      "loss.mean=0.01618980467022525\n",
      "loss.mean=0.016077712958213478\n",
      "loss.mean=0.015967155921794315\n",
      "loss.mean=0.01585810236484795\n",
      "loss.mean=0.01575052192874081\n",
      "loss.mean=0.015644385064474006\n",
      "loss.mean=0.015539663005933783\n",
      "loss.mean=0.015436327744193573\n",
      "loss.mean=0.01533435200281947\n",
      "loss.mean=0.015233709214134326\n",
      "loss.mean=0.015134373496396783\n",
      "loss.mean=0.01503631963185501\n",
      "loss.mean=0.01493952304563594\n",
      "loss.mean=0.014843959785433401\n",
      "loss.mean=0.014749606501959991\n",
      "loss.mean=0.014656440430129697\n",
      "loss.mean=0.014564439370939297\n",
      "loss.mean=0.014473581674018956\n",
      "loss.mean=0.014383846220822867\n",
      "loss.mean=0.014295212408433188\n",
      "loss.mean=0.014207660133951264\n",
      "loss.mean=0.014121169779451275\n",
      "loss.mean=0.014035722197473144\n",
      "loss.mean=0.01395129869703203\n",
      "loss.mean=0.013867881030123463\n",
      "loss.mean=0.013785451378703337\n",
      "loss.mean=0.013703992342123853\n",
      "loss.mean=0.013623486925006603\n",
      "loss.mean=0.013543918525535319\n",
      "loss.mean=0.01346527092415148\n",
      "loss.mean=0.013387528272636603\n",
      "loss.mean=0.013310675083566098\n",
      "loss.mean=0.01323469622011976\n",
      "loss.mean=0.0131595768862352\n",
      "loss.mean=0.013085302617090703\n",
      "loss.mean=0.013011859269904724\n",
      "loss.mean=0.012939233015039884\n",
      "loss.mean=0.012867410327399813\n",
      "loss.mean=0.01279637797810753\n",
      "loss.mean=0.012726123026454848\n",
      "loss.mean=0.012656632812112484\n",
      "loss.mean=0.01258789494759116\n",
      "loss.mean=0.012519897310944108\n",
      "loss.mean=0.012452628038702413\n",
      "loss.mean=0.012386075519034256\n",
      "loss.mean=0.012320228385119836\n",
      "loss.mean=0.012255075508734418\n",
      "loss.mean=0.012190605994031439\n",
      "loss.mean=0.012126809171519\n",
      "loss.mean=0.0120636745922221\n",
      "loss.mean=0.012001192022024779\n",
      "loss.mean=0.01193935143618497\n",
      "loss.mean=0.01187814301401639\n",
      "loss.mean=0.0118175571337316\n",
      "loss.mean=0.011757584367440286\n",
      "loss.mean=0.011698215476297546\n",
      "loss.mean=0.011639441405797006\n",
      "[0.98220008 0.98914591 0.98784866 0.98994175 0.98814767 0.98402968\n",
      " 0.99241998 0.99096855 0.99024439 0.98579524 0.98624713 0.98552195\n",
      " 0.98075878 0.98731766 0.99283052 0.98889658 0.98827467 0.98957215\n",
      " 0.98479576 0.99400419 0.99163609 0.99026408 0.98248034 0.98671119\n",
      " 0.99117738 0.98442763 0.99093569 0.98891117 0.99003922 0.98846194\n",
      " 0.9912716  0.99357503 0.98402122 0.98248401 0.99097786 0.99190655\n",
      " 0.99118975 0.9847117  0.98796652 0.98081899 0.99163717 0.9934478\n",
      " 0.98560617 0.98819051 0.98910928 0.99366274 0.98601755 0.98457437\n",
      " 0.9870861  0.99152144 0.98841443 0.98202767 0.98374525 0.99218177\n",
      " 0.98858125 0.98907916 0.99246932 0.9904932  0.98839837 0.99084485\n",
      " 0.98905485 0.98920848 0.98752432 0.98359198 0.99195273 0.98846358\n",
      " 0.98900368 0.98907563 0.98869803 0.98776137 0.98966892 0.98787601\n",
      " 0.98628215 0.97902346 0.98683581 0.99093421 0.99078953 0.98913811\n",
      " 0.98902427 0.98917213 0.99042062 0.99151724 0.98235334 0.99117985\n",
      " 0.98732021 0.99191267 0.98463816 0.99414644 0.99183126 0.99028123\n",
      " 0.9915656  0.98820156 0.98370605 0.98328275 0.99042703 0.99200288\n",
      " 0.98702777 0.99288004 0.98956826 0.99261021 0.01329987 0.01334085\n",
      " 0.00735888 0.01518442 0.01088064 0.00766027 0.00737937 0.01382561\n",
      " 0.0094584  0.01194246 0.01625107 0.01397859 0.01484055 0.00848849\n",
      " 0.0052528  0.00701322 0.01054256 0.00916361 0.01056227 0.01124545\n",
      " 0.00837747 0.0098016  0.01375705 0.00755144 0.01551411 0.01159374\n",
      " 0.01742612 0.01022163 0.01886922 0.00916121 0.01194518 0.01189666\n",
      " 0.01904437 0.01058683 0.00823986 0.00914683 0.01002033 0.01507149\n",
      " 0.00916158 0.00951872 0.02007275 0.01537865 0.01317648 0.0112698\n",
      " 0.02176571 0.01091054 0.01336452 0.0102787  0.0161119  0.01427742\n",
      " 0.0088379  0.0176116  0.00899739 0.01224952 0.00877218 0.01032929\n",
      " 0.00820636 0.01231152 0.00884252 0.01179837 0.00874078 0.0090226\n",
      " 0.00969001 0.01483568 0.01473575 0.00970261 0.01005969 0.01082173\n",
      " 0.00820509 0.01703015 0.01367785 0.01364219 0.00810362 0.01457592\n",
      " 0.00483769 0.01867849 0.01222907 0.00773975 0.00679756 0.01629144\n",
      " 0.00850118 0.00899571 0.01213513 0.00921392 0.01386929 0.01200847\n",
      " 0.00794983 0.01295567 0.01213244 0.01069651 0.01984696 0.00525442\n",
      " 0.00827563 0.010613   0.0064153  0.0122428  0.01208292 0.00915224\n",
      " 0.01444918 0.00832591]\n"
     ]
    }
   ],
   "source": [
    "# Linear Binary Classification\n",
    "# Given a set of N points in the D-dimensional space and their labels of boolean values, find a hyperplane that separates the true and false class. Return a classifier that takes in a point vector and returns probility.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def binary_classifier_from(X, Y):\n",
    "    '''\n",
    "        X, a float np.array of shape [N, D]\n",
    "        Y, a boolean array of labels, shape [N]\n",
    "    '''\n",
    "    epsilon = 1e-5\n",
    "\n",
    "    D = X.shape[1]\n",
    "\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(D)  # D,\n",
    "    b = 0  # 1\n",
    "\n",
    "    lr = 0.001\n",
    "\n",
    "    def sigmoid(x):\n",
    "        return (1 + np.exp(-x)) ** -1\n",
    "    def d_sigmoid(x):\n",
    "        # -1 * (1 + np.exp(-x)) ** -2 * np.exp(-x) * -1\n",
    "        # return sigmoid(x) ** 2 * np.exp(-x)  \n",
    "        return  sigmoid(x) * (1 -  sigmoid(x))\n",
    "    \n",
    "    m = X.mean(0)\n",
    "    std = X.std()\n",
    "\n",
    "    def forward(vectors):\n",
    "        standardized_v = (vectors - m) / (std + epsilon)\n",
    "        logit = standardized_v @ W + b  # N\n",
    "        prob = sigmoid(logit)  # N\n",
    "        return prob\n",
    "\n",
    "    for i in range(200):\n",
    "        # Forward\n",
    "        prob = forward(X)  # N\n",
    "        labels = Y * 1.0\n",
    "        loss = - labels * np.log(prob + epsilon) - (1 - labels) * np.log(1 - prob + epsilon)\n",
    "\n",
    "        # Backward\n",
    "        standardized_x = (X - m) / (std + epsilon)\n",
    "        # d_prob = - labels / (prob + epsilon) + (1 - labels) / (1 - prob + epsilon)  # N\n",
    "        # d_logit = prob * (1 - prob) * d_prob # N\n",
    "        d_logit = prob - labels\n",
    "        d_W = standardized_x.T @ d_logit  # D\n",
    "        d_b = d_logit.sum()\n",
    "\n",
    "        W -= lr * d_W\n",
    "        b -= lr * d_b\n",
    "\n",
    "        print(f\"loss.mean={loss.mean()}\")\n",
    "        # break\n",
    "\n",
    "    return forward\n",
    "\n",
    "\n",
    "# train_data = np.array([\n",
    "#     [0, 1], [1, 2], [3, 4], [1, 1], [2, 3],\n",
    "# ], dtype=float)\n",
    "# train_labels = np.array([True, True, True, False, True])\n",
    "\n",
    "# train_data = np.array([\n",
    "#     [0, 1], [1, 2],\n",
    "# ], dtype=float)\n",
    "# train_labels = np.array([True, False])\n",
    "\n",
    "train_data = np.concatenate(\n",
    "    [\n",
    "        np.random.randn(100, 10) + np.array([50, 20] + [0] * 8, dtype=float),\n",
    "        np.random.randn(100, 10) + np.array([20, 0] + [0] * 8, dtype=float),\n",
    "    ], axis=0)\n",
    "train_labels = np.array([True] * 100 + [False] * 100)\n",
    "\n",
    "model = binary_classifier_from(train_data, train_labels)\n",
    "print(model(train_data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With \n",
    "        d_prob = - labels / (prob + epsilon) + (1 - labels) / (1 - prob + epsilon)  # N\n",
    "        d_logit = prob * (1 - prob) * d_prob # N\n",
    "in the backprob, it's very same:\n",
    "\n",
    "loss.mean=0.47989471852639026\n",
    "loss.mean=0.4190224805366235\n",
    "loss.mean=0.3698198680071503\n",
    "loss.mean=0.32959864629758917\n",
    "loss.mean=0.2963408932624755\n",
    "loss.mean=0.26853386425829784\n",
    "loss.mean=0.24503870297758878\n",
    "loss.mean=0.22499161669233395\n",
    "loss.mean=0.20773139806909896\n",
    "loss.mean=0.1927468346361424\n",
    "loss.mean=0.17963862408216955\n",
    "loss.mean=0.16809170825330783\n",
    "loss.mean=0.1578550528428587\n",
    "loss.mean=0.14872675337547514"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ajax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
