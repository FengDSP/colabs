{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.mean=0.49327979935882843\n",
      "loss.mean=0.4300982489899032\n",
      "loss.mean=0.379073917596292\n",
      "loss.mean=0.33741172147415893\n",
      "loss.mean=0.3030068152120189\n",
      "loss.mean=0.2742787855368652\n",
      "loss.mean=0.2500371967978292\n",
      "loss.mean=0.22937926513697066\n",
      "loss.mean=0.21161433266603658\n",
      "loss.mean=0.19620886337869745\n",
      "loss.mean=0.18274653013624026\n",
      "loss.mean=0.17089919281291743\n",
      "loss.mean=0.1604056814658728\n",
      "loss.mean=0.15105617130918642\n",
      "loss.mean=0.14268057874831006\n",
      "loss.mean=0.13513986658413704\n",
      "loss.mean=0.12831946969866062\n",
      "loss.mean=0.12212427908225157\n",
      "loss.mean=0.11647478092383182\n",
      "loss.mean=0.11130405928321413\n",
      "loss.mean=0.10655544997945837\n",
      "loss.mean=0.10218068969263559\n",
      "loss.mean=0.09813844472992869\n",
      "loss.mean=0.09439313316786951\n",
      "loss.mean=0.09091397541555747\n",
      "loss.mean=0.0876742239203378\n",
      "loss.mean=0.08465053434776224\n",
      "loss.mean=0.08182244923248602\n",
      "loss.mean=0.0791719716116957\n",
      "loss.mean=0.0766832110866535\n",
      "loss.mean=0.07434208852081124\n",
      "loss.mean=0.0721360884720691\n",
      "loss.mean=0.07005405068945969\n",
      "loss.mean=0.06808599374077444\n",
      "loss.mean=0.06622296519594607\n",
      "loss.mean=0.06445691385978167\n",
      "loss.mean=0.06278058039328846\n",
      "loss.mean=0.06118740333551523\n",
      "loss.mean=0.059671438075670616\n",
      "loss.mean=0.05822728675742864\n",
      "loss.mean=0.05685003744621109\n",
      "loss.mean=0.055535211173173823\n",
      "loss.mean=0.05427871570009334\n",
      "loss.mean=0.05307680503787397\n",
      "loss.mean=0.05192604390623608\n",
      "loss.mean=0.05082327644981904\n",
      "loss.mean=0.04976559863160366\n",
      "loss.mean=0.04875033381233774\n",
      "loss.mean=0.04777501109782043\n",
      "loss.mean=0.04683734609710522\n",
      "loss.mean=0.045935223786040265\n",
      "loss.mean=0.045066683213801396\n",
      "loss.mean=0.04422990382658014\n",
      "loss.mean=0.043423193213508536\n",
      "loss.mean=0.042644976106160096\n",
      "loss.mean=0.04189378448533155\n",
      "loss.mean=0.04116824866790616\n",
      "loss.mean=0.04046708926295034\n",
      "loss.mean=0.03978910990022911\n",
      "loss.mean=0.03913319064639918\n",
      "loss.mean=0.03849828203455357\n",
      "loss.mean=0.03788339964179151\n",
      "loss.mean=0.03728761915728661\n",
      "loss.mean=0.036710071890096306\n",
      "loss.mean=0.0361499406718463\n",
      "loss.mean=0.03560645611455835\n",
      "loss.mean=0.0350788931883767\n",
      "loss.mean=0.034566568087873416\n",
      "loss.mean=0.034068835359056\n",
      "loss.mean=0.03358508526222472\n",
      "loss.mean=0.033114741348488\n",
      "loss.mean=0.03265725823009076\n",
      "loss.mean=0.03221211952678136\n",
      "loss.mean=0.03177883597227589\n",
      "loss.mean=0.03135694366650076\n",
      "loss.mean=0.030946002460735263\n",
      "loss.mean=0.03054559446405531\n",
      "loss.mean=0.030155322660618173\n",
      "loss.mean=0.02977480962834321\n",
      "loss.mean=0.029403696350449447\n",
      "loss.mean=0.02904164111212002\n",
      "loss.mean=0.0286883184752884\n",
      "loss.mean=0.02834341832519004\n",
      "loss.mean=0.028006644982905976\n",
      "loss.mean=0.027677716378647684\n",
      "loss.mean=0.02735636328100358\n",
      "loss.mean=0.027042328577791125\n",
      "loss.mean=0.026735366604540598\n",
      "loss.mean=0.026435242516981785\n",
      "loss.mean=0.026141731704216204\n",
      "loss.mean=0.02585461923953967\n",
      "loss.mean=0.025573699366135304\n",
      "loss.mean=0.025298775015088523\n",
      "loss.mean=0.025029657353385682\n",
      "loss.mean=0.02476616535974906\n",
      "loss.mean=0.02450812542633394\n",
      "loss.mean=0.024255370984472086\n",
      "loss.mean=0.024007742152789478\n",
      "loss.mean=0.02376508540615744\n",
      "loss.mean=0.023527253264056077\n",
      "loss.mean=0.023294103997038636\n",
      "loss.mean=0.023065501350085\n",
      "loss.mean=0.022841314281724562\n",
      "loss.mean=0.022621416717892185\n",
      "loss.mean=0.022405687319558408\n",
      "loss.mean=0.022194009263244826\n",
      "loss.mean=0.02198627003360116\n",
      "loss.mean=0.0217823612272794\n",
      "loss.mean=0.021582178367395587\n",
      "loss.mean=0.021385620727919958\n",
      "loss.mean=0.021192591167382497\n",
      "loss.mean=0.02100299597132401\n",
      "loss.mean=0.020816744702961954\n",
      "loss.mean=0.02063375006157675\n",
      "loss.mean=0.02045392774815815\n",
      "loss.mean=0.020277196337881973\n",
      "loss.mean=0.020103477159016322\n",
      "loss.mean=0.0199326941778834\n",
      "loss.mean=0.019764773889527062\n",
      "loss.mean=0.019599645213759405\n",
      "loss.mean=0.019437239396281114\n",
      "loss.mean=0.019277489914589174\n",
      "loss.mean=0.019120332388404698\n",
      "loss.mean=0.018965704494369757\n",
      "loss.mean=0.018813545884778488\n",
      "loss.mean=0.01866379811012185\n",
      "loss.mean=0.018516404545239503\n",
      "loss.mean=0.018371310318884605\n",
      "loss.mean=0.018228462246519365\n",
      "loss.mean=0.018087808766170055\n",
      "loss.mean=0.017949299877180584\n",
      "loss.mean=0.01781288708171331\n",
      "loss.mean=0.01767852332885465\n",
      "loss.mean=0.017546162961191228\n",
      "loss.mean=0.017415761663730826\n",
      "loss.mean=0.017287276415048583\n",
      "loss.mean=0.01716066544054686\n",
      "loss.mean=0.017035888167722755\n",
      "loss.mean=0.016912905183343704\n",
      "loss.mean=0.016791678192436987\n",
      "loss.mean=0.016672169979004357\n",
      "loss.mean=0.016554344368377813\n",
      "loss.mean=0.016438166191137246\n",
      "loss.mean=0.01632360124851509\n",
      "loss.mean=0.016210616279216942\n",
      "loss.mean=0.016099178927591263\n",
      "loss.mean=0.015989257713084615\n",
      "loss.mean=0.015880822000922425\n",
      "loss.mean=0.015773841973958373\n",
      "loss.mean=0.01566828860563851\n",
      "loss.mean=0.01556413363402897\n",
      "loss.mean=0.01546134953685901\n",
      "loss.mean=0.01535990950753333\n",
      "loss.mean=0.0152597874320701\n",
      "loss.mean=0.015160957866923461\n",
      "loss.mean=0.015063396017651125\n",
      "loss.mean=0.01496707771838985\n",
      "loss.mean=0.014871979412103395\n",
      "loss.mean=0.014778078131569275\n",
      "loss.mean=0.014685351481072337\n",
      "loss.mean=0.014593777618774713\n",
      "loss.mean=0.014503335239733274\n",
      "loss.mean=0.014414003559537062\n",
      "loss.mean=0.0143257622985383\n",
      "loss.mean=0.014238591666652397\n",
      "loss.mean=0.014152472348702837\n",
      "loss.mean=0.01406738549028853\n",
      "loss.mean=0.013983312684152056\n",
      "loss.mean=0.013900235957028028\n",
      "loss.mean=0.013818137756952344\n",
      "loss.mean=0.013737000941013301\n",
      "loss.mean=0.013656808763526946\n",
      "loss.mean=0.013577544864619514\n",
      "loss.mean=0.013499193259200837\n",
      "loss.mean=0.01342173832631319\n",
      "loss.mean=0.013345164798840625\n",
      "loss.mean=0.013269457753564879\n",
      "loss.mean=0.013194602601554233\n",
      "loss.mean=0.0131205850788723\n",
      "loss.mean=0.01304739123759462\n",
      "loss.mean=0.012975007437121015\n",
      "loss.mean=0.012903420335772676\n",
      "loss.mean=0.012832616882662911\n",
      "loss.mean=0.012762584309831387\n",
      "loss.mean=0.012693310124631969\n",
      "loss.mean=0.012624782102364552\n",
      "loss.mean=0.012556988279141987\n",
      "loss.mean=0.012489916944983328\n",
      "loss.mean=0.012423556637125\n",
      "loss.mean=0.012357896133542122\n",
      "loss.mean=0.012292924446672073\n",
      "loss.mean=0.012228630817333228\n",
      "loss.mean=0.012165004708831697\n",
      "loss.mean=0.012102035801249265\n",
      "loss.mean=0.012039713985906314\n",
      "loss.mean=0.011978029359993245\n",
      "loss.mean=0.01191697222136455\n",
      "loss.mean=0.011856533063490014\n",
      "loss.mean=0.011796702570557151\n",
      "loss.mean=0.01173747161271998\n",
      "[0.98461203 0.98858334 0.99208154 0.98721134 0.99141622 0.98600701\n",
      " 0.98774429 0.98903086 0.9861178  0.98563135 0.98598786 0.98648963\n",
      " 0.98780783 0.98892693 0.99104285 0.98220451 0.98571813 0.99315551\n",
      " 0.98122609 0.99050219 0.98133518 0.98423585 0.99023269 0.99056507\n",
      " 0.98594985 0.98976561 0.99135181 0.99048268 0.98642707 0.99094124\n",
      " 0.98587188 0.99038537 0.98865074 0.98484317 0.98593805 0.99161127\n",
      " 0.9900203  0.99121694 0.99023031 0.99285909 0.99020446 0.98911405\n",
      " 0.99164545 0.99514284 0.98925186 0.98816156 0.98546745 0.98685174\n",
      " 0.9838267  0.98901005 0.98286459 0.99591135 0.98723589 0.98967426\n",
      " 0.98622979 0.99282745 0.99140578 0.98863388 0.98763193 0.98994098\n",
      " 0.98907426 0.98995144 0.98622993 0.98898375 0.98932806 0.98939261\n",
      " 0.99287398 0.98886014 0.9860374  0.98553733 0.98943258 0.98625256\n",
      " 0.98608227 0.98026647 0.9879964  0.99086161 0.9873451  0.99018285\n",
      " 0.98954803 0.98713258 0.9882642  0.98779014 0.99242509 0.98856091\n",
      " 0.98747688 0.9851174  0.98707408 0.98438459 0.98640481 0.99272877\n",
      " 0.98836674 0.99082081 0.98961113 0.99072132 0.98956376 0.991998\n",
      " 0.99046443 0.98614904 0.99054289 0.99339672 0.009865   0.00658814\n",
      " 0.01335922 0.00933637 0.00890977 0.01303874 0.00819319 0.00850385\n",
      " 0.01482787 0.01542831 0.01138258 0.01494475 0.00862796 0.01136404\n",
      " 0.01698456 0.01813542 0.01242151 0.01364483 0.01043761 0.0151803\n",
      " 0.0102104  0.0168262  0.01728658 0.01856239 0.00932192 0.01175964\n",
      " 0.0097897  0.02649443 0.01256518 0.00597679 0.00774617 0.0119002\n",
      " 0.00526065 0.00461002 0.01347054 0.0076671  0.00905678 0.01075742\n",
      " 0.00953279 0.0090447  0.00663971 0.00912833 0.01190551 0.01303725\n",
      " 0.01516968 0.01791531 0.00681073 0.01319359 0.0120994  0.00967389\n",
      " 0.00594896 0.01208516 0.01149203 0.01990845 0.02159911 0.0084141\n",
      " 0.00913469 0.01099204 0.00925347 0.01300166 0.00815023 0.0102756\n",
      " 0.01191307 0.01982126 0.01597162 0.0096052  0.00791659 0.00991074\n",
      " 0.0145333  0.00915586 0.00735488 0.01288898 0.00848909 0.01990886\n",
      " 0.00733353 0.00794869 0.01136931 0.00809831 0.0090611  0.01138164\n",
      " 0.00859895 0.03637929 0.01177591 0.01030236 0.00730922 0.00875482\n",
      " 0.02194237 0.00688948 0.01141859 0.00641922 0.01327676 0.01126881\n",
      " 0.01114266 0.00862432 0.00447067 0.01233793 0.01256529 0.01494326\n",
      " 0.00798899 0.01734644]\n"
     ]
    }
   ],
   "source": [
    "# Linear Binary Classification\n",
    "# Given a set of N points in the D-dimensional space and their labels of boolean values, find a hyperplane that separates the true and false class. Return a classifier that takes in a point vector and returns probility.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def binary_classifier_from(X, Y):\n",
    "    '''\n",
    "        X, a float np.array of shape [N, D]\n",
    "        Y, a boolean array of labels, shape [N]\n",
    "    '''\n",
    "    epsilon = 1e-5\n",
    "\n",
    "    D = X.shape[1]\n",
    "\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(D)  # D,\n",
    "    b = 0  # 1\n",
    "\n",
    "    lr = 0.001\n",
    "\n",
    "    def sigmoid(x):\n",
    "        return (1 + np.exp(-x)) ** -1\n",
    "    def d_sigmoid(x):\n",
    "        # -1 * (1 + np.exp(-x)) ** -2 * np.exp(-x) * -1\n",
    "        # return sigmoid(x) ** 2 * np.exp(-x)  \n",
    "        return  sigmoid(x) * (1 -  sigmoid(x))\n",
    "    \n",
    "    m = X.mean(0)\n",
    "    std = X.std()\n",
    "\n",
    "    def forward(vectors):\n",
    "        standardized_v = (vectors - m) / (std + epsilon)\n",
    "        logit = standardized_v @ W + b  # N\n",
    "        prob = sigmoid(logit)  # N\n",
    "        return prob\n",
    "\n",
    "    for i in range(200):\n",
    "        # Forward\n",
    "        prob = forward(X)  # N\n",
    "        labels = Y * 1.0\n",
    "        loss = - labels * np.log(prob + epsilon) - (1 - labels) * np.log(1 - prob + epsilon)\n",
    "\n",
    "        # Backward\n",
    "        standardized_x = (X - m) / (std + epsilon)\n",
    "        d_prob = - labels / (prob + epsilon) + (1 - labels) / (1 - prob + epsilon)  # N\n",
    "        d_logit = prob * (1 - prob) * d_prob # N\n",
    "        d_W = standardized_x.T @ d_logit  # D\n",
    "        d_b = d_logit.sum()\n",
    "\n",
    "        W -= lr * d_W\n",
    "        b -= lr * d_b\n",
    "\n",
    "        print(f\"loss.mean={loss.mean()}\")\n",
    "        # break\n",
    "\n",
    "    return forward\n",
    "\n",
    "\n",
    "# train_data = np.array([\n",
    "#     [0, 1], [1, 2], [3, 4], [1, 1], [2, 3],\n",
    "# ], dtype=float)\n",
    "# train_labels = np.array([True, True, True, False, True])\n",
    "\n",
    "# train_data = np.array([\n",
    "#     [0, 1], [1, 2],\n",
    "# ], dtype=float)\n",
    "# train_labels = np.array([True, False])\n",
    "\n",
    "train_data = np.concatenate(\n",
    "    [\n",
    "        np.random.randn(100, 10) + np.array([50, 20] + [0] * 8, dtype=float),\n",
    "        np.random.randn(100, 10) + np.array([20, 0] + [0] * 8, dtype=float),\n",
    "    ], axis=0)\n",
    "train_labels = np.array([True] * 100 + [False] * 100)\n",
    "\n",
    "model = binary_classifier_from(train_data, train_labels)\n",
    "print(model(train_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ajax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
